---
title: "Exploring temporal data across bivariate temporal granularities by visualizing probability distribution"
type: "contributed"
author: "<br> Sayani Gupta <br> <i class='fab fa-twitter' style='color:#6CADDE'></i> <i class='fab fa-github'></i> @Sayani07 <br><br><small> https://sayanigupta-iisa.netlify.com/</small>"
date: <font size="5"> Indian Institute of Statistical Association <br> December 26, 2019
output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css", "libs/font-awesome/css/fontawesome-all.css"]
    self_contained: false
    nature:
      ratio: 4:3
      highlightStyle: solarized-dark
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
library(knitr)
options(htmltools.dir.version = FALSE, tibble.width = 55, tibble.print_min = 4)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = 'figure/', cache.path = 'cache/', fig.align = 'center', 
  fig.width = 12, fig.show = 'hold', fig.height = 7, # 16:9
  cache = TRUE, external = TRUE, dev = 'svglite'
)
read_chunk('R/theme.R')
read_chunk('R/main.R')
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
solarized_dark(
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Droid Mono"),
  header_color = "#FFFFE0",
  text_color = "#FFDAB9"
  
)
```

# Electricity smart meter technology  (~ 40 billion half hourly observations)

<!-- .pull-left[ -->
<!-- .center-left[ -->
- Source : Department of the Environment and Energy, Australia
<br>
<br>
- Frequency:  Half hourly (interval meter reading (Kwh))
<br>
<br>
- Time Span: 2012 to 2014
<br>
<br>
- Spread: 14K (approx.) households based in Newcastle, New South Wales, and parts of Sydney
<br>
<br>

???
Smart meters record electricity usage (per kWh) every 30 minutes and send this information to the electricity retailer for billing

**Consumers** can save considerable amount on their electricity bill by 
- Switching on their hot water heater or do laundry when energy is cheaper, or when their solar system is generating surplus energy 
- Switching off appliances during peak demands
- Check usage and compare with similar homes 

**Retailers** can reduce costs and increase efficiency
- Lowering metering and connection fees 
- Drawing insights into when customer is home, or sleeping, or even what appliances they are using based on usage figures
- Rewarding customers for mindful usage

Just to give you some perspective I have this data from Department of Energy and Environment, Australia that provides interval meter reading data every 30 minutes from 2012 to 2014. So you can think of it like, that the finest temporal unit here is half hour, whereas the coarsest temporal unit is year. This data is made available for 14k customers located in different local government areas across places.. So this is a data which is spread across both time and space and hence is a spatio-temporal data. 

---
<!-- class: hide-slide-number -->

## Visualize the raw data from from 2012 - 2014 for 50 households

```{r load}

```


```{r motivation3}
```

---
<!-- class: hide-slide-number -->



## Visualize the periodicities in half-hourly energy usage for 1 household from 2012 to 2014

```{r motivation5}
```

---


background-image: url("images/problem.png")

background-position: center
background-size: contain



???
Well, there can be numerous ways to analyse this data! But I was interested in answering the question - that given this huge volume and spread, how can one explore this data systematically?

---

class: center,middle


##  **Problem** :  <span style="color:#FFDAB9"> How do we systematically explore large quantities of temporal data across different deconstructions of time (half-hour, day, type of day, year) to find regular patterns or anomalies in behaviour? 

## **Solution** : <span style="color:#FFDAB9"> Visualize probability distributions over different time granularities.

???

Developed by **John Tukey** as a way of _*systematically*_ using the tools of statistics on a problem before a hypotheses about the data were developed. This encourages to break the big problem into pieces and focusing on subsets. So the reduced goal that I set for myself is to look at time only and to provide ... . The smart meter example is the one that motivated me for this problem, how the idea is to provide the same for any temporal data following an hierarchy. 

The key terms are decontructing time and visualizing distribution. In the next couples of slides, we will talk about the strength and challenges for each of these. 


---

class: inverse middle center

.animated.bounce[
<img src="images/gravitas.png" height=280px>
]

## Visualize probability distributions over different time granularities


---

#  Decontructing time: Arrangement
.pull-left[
#### **Granularities** : abstractions of time based on calendar
<br>
 -  <i> **Linear**</i>  days, weeks, months, years  
<br>
 -  <i> **Circular** </i>   day-of-week, month-of-year or hour-of-day  
<br>
 -  <i> **Quasi-circular** </i>   day-of-month, week-of-month   
<br>

 -  <i> **Aperiodic** </i>  public holidays, school vacations
]

.pull-right[
```{r lineartime, out.width="260%", out.height="150%"}
```
<br>
```{r circulartime, out.width = "100%"}
```


]

---

#  Decontructing time: Order


<i>**Single-order-up**</i> second-of-minute, hour-of-day  
<br>
<i>**Multiple-order-up**</i> second-of-hour, hour-of-week  

```{r calendar, out.height=380, out.width="100%"}

```


---

#  Data Structure for exploration 



---

# Computation of granularities

$z$       : index of a tsibble  
<br>
$x$, $y$  : two units in the hierarchy table with  $order(x) <  order(y)$  
<br>
$f(x, y)$ : accessor function for computing the granularity  
<br>
$c(x, y)$ : a constant which relates x and y  
<br>

#### **Single-order-up**
$$f(x, y) = \lfloor z/c(z,x) \rfloor\mod c(x,y)$$ where $y = x+1$


#### **Multiple-order-up**


\begin{split}
f(x,y) & = \sum_{i=0}^{order(y) - order(x) - 1} c(x, x+i)(f(x
  +i, x+i+1) - 1)\\
\end{split}


---


## Interaction of bivariate granularities

**Harmonies** : pairs of granularities that aid exploratory data analysis  
**Clashes**   : pairs leading to structurally empty sets  

```{r clash, out.width="100%"}

```

---


## Visualizing probability distributions

Breaking down the big problem -  two granularities at a time.


#### Types of statistical distribution plots 


```{r allplot}
```


---


# R package: **gravitas**

.center[
### Computation
--- 

.left[
- Compute any granularity? <span style="color:Red">`create_gran`
 <br>
 <br>
 
- Exhaustive list of granularities to explore? <span style="color:Red"> `search_gran`
 <br>
       ]

]
 
.pull-left[
 ### Interaction
 --- 
 
- Check if bivariate granularities are harmonies/clashes? <span style="color:Red">  `is.harmony`
<br>
<br>
- List of harmonies to explore? <span style="color:Red"> `harmony`
<br>
 ]

.pull-right[
### Visualization
--- 

- Best probability distribution plot for harmonies? 
 <span style="color:Red"> `granplot`
<br>
<br>
- Sufficient observations?  <span style="color:Red">  `gran_obs`

 ]

---

<!-- class: center,middle -->

<!-- # <span style="color:MediumVioletRed"> Package gravitas </span> -->

<!-- ##   granularity visualization of time series data  -->


## An example : Electricity smart meter data

<i><small>Data source</i></small> : [<small><i>Department of the Environment and Energy, Australia</i></small>](https://data.gov.au/dataset/4e21dea3-9b87-4610-94c7-15a8a77907ef)

```{r read}
```

---

### Set of possible temporal granularities

```{r search_gran}
```

### So there are `r length(combn(13,2))` pair of granularities to look at.    <span style="color:Red"> -----> <large> WHAT??? </large>

---

## Set of harmonies

### <span style="color:Orange"><large>  Good news! Only 13 out `r length(combn(13,2))` are harmonies </large>

```{r harmony}
```

---


## Visualize Harmonies


```{r granplotoverlay3}
```

---

## Another example: Cricket data of Indian Premier League

<small><i>Data source</i></small>: [<small><i>Cricsheet</i></small>](http://cricsheet.org/) ,  [<small><i>Kaggle</i></small>](https://www.kaggle.com/josephgpinto/ipl-data-analysis/data)

```{r cricket}
```

---


## Difference in strategy between two top teams


```{r cricketex}
```

---

class: center, middle

### More Information

Package : https://github.com/Sayani07/gravitas  
Slides: https://sayanigupta-ysc.netlify.com/

### With special thanks to 

.pull-left[

#### <span style="color: White"> Supervisors <span style="color: Crimson"> Professor Rob J Hyndman <span style="color: White">  &  <span style="color: Crimson">  Professor Dianne Cook
<br>
#### <span style="color: White"> Slides created with <span style="color: Crimson"><i> Rmarkdown, knitr, xaringan, xaringanthemer</i>
<br>
**<span style="color: Crimson"> Monash University**
]

.pull-right[
### <span style="color: White"> NUMBATS
<br>
```{r numbats, echo=FALSE, out.width="100%"}
  knitr::include_graphics("images/Numbats.png")
```
]

